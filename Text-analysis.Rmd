---
title: "Hate-speech and offensive language on twitter"
author: "Mathias Flinta"
date: "11/10/2019"
output:
  html_document: 
    toc: TRUE
    toc_float: TRUE
    df_print: paged
    code_folding: hide
    number_sections: TRUE
---

# Setup and introduction

Link for google colab: https://colab.research.google.com/drive/1mnp8jrd7AC0lj_j1BnrsHXJi6D9mAzS2 

Link for github: https://github.com/DataEconomistDK/SDS-M2-Mini2

This project is made to be read in html, so open the html file in your preferred webbrowser. As standard the code is hidden in this document, but you can show all by pressing the button "Code" in the top right of the document. You can also show individual chunks of code by pressing the buttons "Code" which are placed around in the document. There is some problems with running code in colab related to the package topic models, just so you are aware. 

I have been on vacation in Israel while making this project, so i had only a few hours to do it, so there is some task missing. Hope you will still enjoy reading it :) 

I set my knitr functions. 
```{r}
### Knitr options
knitr::opts_chunk$set(warning=FALSE,
                     message=FALSE,
                     fig.align="center"
                     )

options(warn=-1) # Hides all warnings, as the knitr options only work on local R-Markdown mode. 

Sys.setenv(LANG = "en")

rm(list=ls())
```

I load my packages. 
```{r}
library(knitr) # For knitr to html
library(rmarkdown) # For formatting the document
library(tidyverse) # Standard datasciewnce toolkid (dplyr, ggplot2 et al.)
library(magrittr) # For advanced piping (%>% et al.)
library(ggraph) # For ggplot2 style graph plotting
library(kableExtra) # Formatting for tables
library(data.table) # for reading in data ect. 

library(tidytext) # Structure text within tidyverse
library(topicmodels) # For topic modelling
library(tm) # text mining library
library(quanteda) # for LSA (latent semantic analysis)
library(uwot) # for UMAP
library(dbscan) # for density based clustering

# I set a seed for reproduciability
set.seed(123) # Have to be set every time a rng proces is being made. 
```

# Preprocessing and vectorization
Justify your choices and explain possible alternatives (e.g. removing stopwords, identifying bi/tri-grams, removing verbs or use of stemming, lemmatization etc.)

First i load my data, rename columns and rename class values to strings of text. 
```{r}
data_raw <- as_tibble(fread("https://transfer.sh/Zgwhy/twitter_hate_speech.csv"))
colnames(data_raw) <- c("ID", "class", "tweet")

data_raw$class <- plyr::mapvalues(data_raw$class, 
                            from = c(0,1,2), 
                            to = c("hate speech", "offensive language", "neither"))
```

Now i try to understand the structure of my data. 
```{r}
head(data_raw, 3)
```
The first column is just a row number ID, that start at 0 index. Second column is the class which is formatted as 0 - hate speech, 1 - offensive language, 2 - neither, which have been labelled by a human. The third column is the tweet text. In total there is 24.783 tweets.  

## Tokenizing by word

First we will tokenize the data by word in a tidy format, to just do some simple analysis about word counts and model som topics. We will here treat the text as a "bag-of-words" where we don't care about the sequence of words. We now have tibble, where each row shows the tweet nr. and a single token. As this is a collection of documents this is called a corpus. 

```{r}
data_tidy <- data_raw %>% 
  unnest_tokens(output = word, input = tweet)
head(data_tidy, 6)
```

Here i have just printed the first 6 rows, and as you can see there is many words that does not cary any semantic meaning by themselves such as "a" or "you" and ect. So here we want to remove suh words by implementing stopwords, so that we only have words that carry semantic meaning by themselves. We now first now remove the most common stopwords by doing a anti join with a stopwords dictionary and also removing some custom stopwords. The custom stopwords are leftovers from the twitter format such as http, but also words i have manually choosen by going through the topwords. Ex. rt is retweet, and http is just the start of a webadress, so these are removed in the custom stopwords. It's hard to remove all, which would require a lot of words or a very specific stop word lexicon, so there will be some stopwords left in the data. 

```{r}
own_stopwords <- tibble(word= c("http", "t.co", "amp", "rt"),
                        lexicon = "OWN")

data_tidy_clean <- data_tidy %>% 
  anti_join(stop_words %>% bind_rows(own_stopwords), by = "word")
```

We also do a bit of general cleaning, in this case removing all special characters, numbers and 1-letter words. This is because these are very contextual and does not really carry meaning in themselves.

With tweets we have a scenario of very high amounts of documents, where each document is very little, especially after cleaning and filtering. This can cause problems later for some analysis, and therefore we need to do some extra filtering. Here i first remove words(rows) that only occur 5 or less times. Then i remove whole tweets that only have 5 or less words after cleaning. This way we have more meaningfull tweets for our analysis.

```{r}
tweets_tidy <- data_tidy_clean %>%
  mutate(word = word %>% str_remove_all("[^[:alnum:]]") ) %>%
  mutate(word = word %>% str_remove_all("[[:digit:]]") ) %>% 
  filter(str_length(word) > 1) %>% 
  add_count(word, name = "nword") %>% 
  filter(nword > 5) %>% 
  add_count(ID, name = "ntweet") %>% 
  filter(ntweet > 5) %>%
  select(-nword, -ntweet)

number_tweets <- tweets_tidy %>% 
  distinct(ID) %>% 
  dim()

tweets_tidy
```
After filtering we have reduced our "bag-of-words" model to only have 66.807 tokens (rows), down from the initial 368.169 tokens in the raw data. This also means our model now includes only ´r number_tweets[1]´ tweets down from the inital 24.783 tweets.

I now create a topwords tibble, by counting up all of the words and see what is the most popular. This can now be plotted to vizualise the top words. 

```{r}
topwords <- tweets_tidy %>% 
  count(word, sort = TRUE)

topwords %>%
  top_n(20, n) %>%
  ggplot(aes(x = word %>% fct_reorder(n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(title = "Word Counts",
       x = "Frequency",
       y = "Top Words")
```
As we might expect there is a lot of swear words in these tweets. Also there might be a lot slang words and different variations of the same words, as this is a tendency on the internet and especially twitter where you are more limited in the amount of text. 

## TF-IDF
Know we want to do a tf-idf analysis. Here tf is "term frequency", which is just the count of how often the word occurs in a document. Then idf is the "inverse document frequency", which decreases the weight for commonly used words and increases the weight for words that are not used very much in a collection of document. These 2 metrics are multiplied by each other to form tf-idf. So tf-idf then becomes a relative frequency metric. If the metric is high then a given word appears often in a document, compared to the rest of the documents. 

Below i count how many times the word appear in each tweet (n), the total words in each tweet (total), the term frequency (tf), the inverse document frequency (idf) and finally the tf-idf which is the metric we want. 

```{r}
tweets_tidy_count <- tweets_tidy %>% 
  count(ID, word, sort = TRUE)

tweets_tidy_sum <- tweets_tidy %>% 
  count(ID, word, sort = TRUE) %>% 
  group_by(ID) %>% 
  summarize(total = sum(n))

tweet_tidy_total <- left_join(tweets_tidy_count, tweets_tidy_sum) %>% 
  mutate(tf = n/total) %>% 
  bind_tf_idf(word, ID, n)

tweet_tidy_total %>% 
  arrange(desc(tf_idf))
```

We can now try and vizualize the highest tf-idf words in the tweets. 

```{r}
tweet_tidy_total %>% 
  arrange(desc(tf_idf)) %>% 
  mutate(word = factor (word, levels = rev(unique(word)))) %>% 
  top_n(15) %>% 
  ggplot(aes(word, tf_idf)) +
  geom_col(show.legend = TRUE) +
  labs(x = NULL, y = "tf idf") + 
  coord_flip()
```

From this plot we can see that the highest tf-idf words often are slang, abbreviations or similar. These are words we did not see in the top words count plot we made earlier. This is caused by these words being used in only a few tweets very frequent, and others not really using them, as the "authors" of the tweets use very different words. 

## Latent semantic analysis (LSA)
Task: dimensionality reduction (LSA-topic modelling) to transform your corpus into a feature matrix.

We will now perform a LSA, which is less helpful for finding human interpretable topics, but way more stable when attempting to do a dimensionality reduction as preprocessing for supervised ML workflows, or for visualization.

We first create a document-feature matrix. 

```{r}
tweets_dfm <- tweets_tidy %>% 
  count(ID, word) %>% 
  cast_dfm(document = ID, term = word, value = n)

tweets_dfm
```

From there, we can directly execute a LDA with the quanteda function textmodel_lsa. We here set the nd argument to 5, which is the amount of dimensions to be included in the output. 

```{r}
tweets_lsa <- tweets_dfm %>%
  textmodel_lsa(nd = 5)

tweets_lsa_loading <- tweets_lsa$docs %>%
  as.data.frame() %>%
  rownames_to_column(var = "ID") %>%
  as_tibble()

tweets_lsa_umap <- umap(tweets_lsa_loading %>% 
                        column_to_rownames("ID"),
                        n_neighbors = 15,
                        metric = "cosine",
                        min_dist = 0.01,
                        scale = TRUE,
                        verbose = TRUE, n_threads = 8)

tweets_lsa_umap <- tweets_lsa_umap %>% as.data.frame()
```

Now we have performed our LSA which we can now plot as seen below. 
```{r}
tweets_lsa_hdbscan <- tweets_lsa_umap %>% as.matrix() %>% hdbscan(minPts = 500)

tweets_lsa_umap %>%
  bind_cols(cluster = tweets_lsa_hdbscan$cluster %>% as.factor(),
            prob = tweets_lsa_hdbscan$membership_prob) %>%
  ggplot(aes(x = V1, y = V2, col = cluster)) +
  geom_point(aes(alpha = prob), shape = 21)
```
The plot is hard to interpret by us humans, but can be used in the supervised ML part. But we can see that the appears to be significant clusters, marked by the different colours in the 2 dimensions V1 and V2 out of the total 5 dimensions. 

## Word-embedding model
Train a word-embedding model of your choice (Word2Vec, GloVe or Fasttext) and use it to calculate average-vector-representations for the tweets.

Here i will use GloVe to make a word-embedding model.

We now want a document term matrix (DTM), which we will need for this analysis. DTM can be described as:

- each row represents one document (each tweet).

- each column represents one term.

- each value (typically) contains the number of appearances of that term in that document.

Since most pairings of document and term do not occur (they have the value zero), DTMs are usually implemented as sparse matrices.

I here use our tidy tweet data and transform it into a dfm. I also define the features. 

```{r}
tweets_dfm <- tweets_tidy %>% 
  count(ID, word) %>% 
  cast_dfm(document = ID, term = word, value = n)

feats <- tweets_dfm %>% 
  featnames()

tweets_dfm
```
Did not have time to do more for this task. 

# Explore and compare the 2 "classes of interest" - hate speech vs offensive language.

## Differences by simple count
Can you see differences by using simple count-based approaches?

```{r}
topwords_class <- tweets_tidy %>% 
  group_by(class) %>% 
  count(word, sort = TRUE)

topwords_class %>%
  group_by(class) %>%
  top_n(10) %>%
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n), fill = class) +
  geom_col() +
  coord_flip() +
  labs(title = "Word Counts",
       x = "Frequency",
       y = "Top Words") +
  facet_wrap(~class, scales = "free")
```

As can be seen from the 3 plots of word counts, "hate speech" and "offensive language" appears to be quite similar in the top words. These are swearing words or similar. The class "neither" don't have any similarities with the other classes, and have what appears to be more neutral words. 

## Identifying themes for each class
Can you identify themes (aka clusters / topics) that are specific for one class or another? Explore them using, e.g. simple crosstabs - topic vs. class and to get more detailed insights within-cluster top (TF-IDF) terms. (This step requires preprocessed/tokenized inputs).

We can use unsupervised machinelearning (similar to clustering) to find topics. It searches for patterns within words. It then calculates probabilities that words will occur together. Based on discrete variables (the word counts). Every document is a misture (partial member) of every topic. 

Here i decide on using Latent Dirichlet allocation (LDA). Here we imagine that each tweet each contain words from several topics in a particular proportion. Here each topic is a mixture of words, which could relate to the classes "hate speech", "offensive language" and "neither". 

I here make a 2 topic model with LDA. Here we calculate the beta, which is how a each term relate to each topic by a certain proportion. 

```{r}
tweets_dfm

tweet_lda <- LDA(tweets_dfm, k = 2, control = list(seed = 123))
tweet_lda

tweet_topics <- tidy(tweet_lda, matrix = "beta")
tweet_topics
```

I now calculate the top words used in each topic and plot them as below. 

```{r}
tweet_top_terms <- tweet_topics %>% 
  group_by(topic) %>% 
  top_n(10, beta) %>% 
  ungroup() %>% 
  arrange(topic, -beta)

tweet_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()
```

We see that both includes many of the same swear words, so it does not seem to seperate well, on the top words at least. 

To try and understand the topics better i calculate the greatest difference in beta between topic 1 and 2. 

```{r}
beta_spread <- tweet_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1))

beta_spread %>%
  group_by(direction = log_ratio > 0) %>%
  top_n(10, abs(log_ratio)) %>%
  ungroup() %>%
  mutate(term = reorder(term, log_ratio)) %>%
  ggplot(aes(term, log_ratio)) +
  geom_col() +
  labs(y = "Log2 ratio of beta in topic 2 / topic 1") +
  coord_flip()
```

We see that many of the words that relate very different between topics are many neutral words, but also some hard words such as retarded. 

# Predicing hate speech by using superved ML 

Use the ML pipeline (learned in M1) to build a classification model that can identify offensive language and hate speech. It is not an easy task to get good results. Experiment with different models on the two types of text-representations that you create in 2.

Here advanced NLP feature engineering has been used, and thus everything around an overall accuracy of 85 is fine. You will see that it is not easy to lift class 0 accuracy over 0.5

I did not have time for this. 




